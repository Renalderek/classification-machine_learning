{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFPL25ds9OGdb1m4ZuywJZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renalderek/classification-machine_learning/blob/main/RockPaperScissor_Reinalto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5xRdgrl0usng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0bf3ff-d544-4121-d2ff-7861938f1d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinalto Derek\n",
            "renalderek@gmail.com\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "nama = 'Reinalto Derek'\n",
        "email = 'renalderek@gmail.com'\n",
        "print(nama)\n",
        "print(email)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget no--check--certificate \\\n",
        "https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVSbewbGycif",
        "outputId": "9ef94f39-04d2-4452-d700-86b468921d4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-13 23:34:31--  http://no--check--certificate/\n",
            "Resolving no--check--certificate (no--check--certificate)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘no--check--certificate’\n",
            "--2023-11-13 23:34:31--  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231113%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231113T233431Z&X-Amz-Expires=300&X-Amz-Signature=abdc5c0b765b591b7a2fd7c3a999f84c485b9932d7b266e5d42e56612e144f83&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-11-13 23:34:31--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231113%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231113T233431Z&X-Amz-Expires=300&X-Amz-Signature=abdc5c0b765b591b7a2fd7c3a999f84c485b9932d7b266e5d42e56612e144f83&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/octet-stream]\n",
            "Saving to: ‘rockpaperscissors.zip’\n",
            "\n",
            "rockpaperscissors.z 100%[===================>] 307.92M   170MB/s    in 1.8s    \n",
            "\n",
            "2023-11-13 23:34:33 (170 MB/s) - ‘rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n",
            "FINISHED --2023-11-13 23:34:33--\n",
            "Total wall clock time: 2.2s\n",
            "Downloaded: 1 files, 308M in 1.8s (170 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_zip = 'rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "5OaypDZA8PQx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/tmp/rockpaperscissors/rps-cv-images/'\n",
        "rock = os.path.join(base_dir, 'rock')\n",
        "paper = os.path.join(base_dir, 'paper')\n",
        "scissors = os.path.join(base_dir, 'scissor')\n"
      ],
      "metadata": {
        "id": "evvnnEbGJH2y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale = 1./255,\n",
        "                    rotation_range = 20,\n",
        "                    horizontal_flip = True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest',\n",
        "                    validation_split = 0.4)\n"
      ],
      "metadata": {
        "id": "rNBzKkJxBar-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        base_dir,\n",
        "        target_size = (150,150),\n",
        "        class_mode = 'categorical',\n",
        "        batch_size = 4,\n",
        "        shuffle = True,\n",
        "        subset = 'training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        base_dir,\n",
        "        target_size = (150,150),\n",
        "        class_mode = 'categorical',\n",
        "        batch_size = 4,\n",
        "        shuffle = True,\n",
        "        subset = 'validation')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkSTmeZxClne",
        "outputId": "49084356-d3dd-4820-c201-df692d92fbf9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1314 images belonging to 3 classes.\n",
            "Found 874 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu',input_shape =(150,150,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128,(3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128,activation = 'relu'),\n",
        "    tf.keras.layers.Dense(512,activation = 'relu'),\n",
        "    tf.keras.layers.Dense(3,activation = 'softmax'),])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gcRF3bBkWaB",
        "outputId": "b933de54-a2c8-4dfb-a31e-567834a97554"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 36992)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               4735104   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               66048     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4895939 (18.68 MB)\n",
            "Trainable params: 4895939 (18.68 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "pAJTPn9joGXD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 25,\n",
        "    epochs = 20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps = 5,\n",
        "    verbose = 2\n",
        ")"
      ],
      "metadata": {
        "id": "6-KvdgGRpDJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73238465-a6dd-48ca-b7f2-2ee669116cea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 11s - loss: 1.1435 - accuracy: 0.3200 - val_loss: 1.1035 - val_accuracy: 0.2500 - 11s/epoch - 446ms/step\n",
            "Epoch 2/20\n",
            "25/25 - 6s - loss: 1.1070 - accuracy: 0.3500 - val_loss: 1.0953 - val_accuracy: 0.4000 - 6s/epoch - 255ms/step\n",
            "Epoch 3/20\n",
            "25/25 - 7s - loss: 1.0961 - accuracy: 0.3061 - val_loss: 1.1856 - val_accuracy: 0.3000 - 7s/epoch - 280ms/step\n",
            "Epoch 4/20\n",
            "25/25 - 8s - loss: 1.0802 - accuracy: 0.4898 - val_loss: 1.2038 - val_accuracy: 0.2500 - 8s/epoch - 340ms/step\n",
            "Epoch 5/20\n",
            "25/25 - 6s - loss: 1.0933 - accuracy: 0.3500 - val_loss: 1.1337 - val_accuracy: 0.3000 - 6s/epoch - 260ms/step\n",
            "Epoch 6/20\n",
            "25/25 - 6s - loss: 1.0077 - accuracy: 0.5200 - val_loss: 0.8489 - val_accuracy: 0.6500 - 6s/epoch - 251ms/step\n",
            "Epoch 7/20\n",
            "25/25 - 7s - loss: 0.8788 - accuracy: 0.5900 - val_loss: 0.6438 - val_accuracy: 0.7500 - 7s/epoch - 276ms/step\n",
            "Epoch 8/20\n",
            "25/25 - 7s - loss: 0.7352 - accuracy: 0.7500 - val_loss: 0.5459 - val_accuracy: 0.7500 - 7s/epoch - 272ms/step\n",
            "Epoch 9/20\n",
            "25/25 - 6s - loss: 0.6288 - accuracy: 0.7500 - val_loss: 0.6272 - val_accuracy: 0.7000 - 6s/epoch - 253ms/step\n",
            "Epoch 10/20\n",
            "25/25 - 7s - loss: 0.5779 - accuracy: 0.7700 - val_loss: 0.4372 - val_accuracy: 0.7500 - 7s/epoch - 262ms/step\n",
            "Epoch 11/20\n",
            "25/25 - 9s - loss: 0.6382 - accuracy: 0.7000 - val_loss: 0.1457 - val_accuracy: 0.9500 - 9s/epoch - 343ms/step\n",
            "Epoch 12/20\n",
            "25/25 - 6s - loss: 0.5666 - accuracy: 0.7900 - val_loss: 0.4946 - val_accuracy: 0.8500 - 6s/epoch - 250ms/step\n",
            "Epoch 13/20\n",
            "25/25 - 8s - loss: 0.4314 - accuracy: 0.8500 - val_loss: 0.2807 - val_accuracy: 0.9000 - 8s/epoch - 329ms/step\n",
            "Epoch 14/20\n",
            "25/25 - 7s - loss: 0.3760 - accuracy: 0.8700 - val_loss: 0.1503 - val_accuracy: 0.9500 - 7s/epoch - 300ms/step\n",
            "Epoch 15/20\n",
            "25/25 - 7s - loss: 0.4424 - accuracy: 0.8600 - val_loss: 0.2424 - val_accuracy: 0.9000 - 7s/epoch - 274ms/step\n",
            "Epoch 16/20\n",
            "25/25 - 6s - loss: 0.3414 - accuracy: 0.9300 - val_loss: 0.0356 - val_accuracy: 1.0000 - 6s/epoch - 243ms/step\n",
            "Epoch 17/20\n",
            "25/25 - 8s - loss: 0.1938 - accuracy: 0.9000 - val_loss: 0.1490 - val_accuracy: 0.9500 - 8s/epoch - 327ms/step\n",
            "Epoch 18/20\n",
            "25/25 - 6s - loss: 0.2855 - accuracy: 0.8980 - val_loss: 0.3786 - val_accuracy: 0.9000 - 6s/epoch - 257ms/step\n",
            "Epoch 19/20\n",
            "25/25 - 8s - loss: 0.2853 - accuracy: 0.9100 - val_loss: 0.3527 - val_accuracy: 0.8500 - 8s/epoch - 323ms/step\n",
            "Epoch 20/20\n",
            "25/25 - 6s - loss: 0.2128 - accuracy: 0.8900 - val_loss: 0.1964 - val_accuracy: 0.9000 - 6s/epoch - 254ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d68f42131f0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  path = fn\n",
        "  img = image.load_img(path,target_size = (150,150))\n",
        "\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "\n",
        "  classes = model.predict(images,batch_size=10)\n",
        "  print(fn)\n",
        "  if classes [0,0] ==1:\n",
        "    print('paper')\n",
        "  elif classes [0,1] ==1:\n",
        "    print('rock')\n",
        "  elif classes [0,2] ==1:\n",
        "    print('Scissors')\n",
        "  else:\n",
        "    print('Tidak Diketahui')\n"
      ],
      "metadata": {
        "id": "C06--2EErL3q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}